{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising and Detoning (of Covariance Matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains a summary of denoising and detoning methods with example codes from Machine Learning for Asset Managers by Marcos Lopez de Prado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Empirical covariance matrices are computed on series of observations from a random vector, in order to estimate the linear comovement between the random variables that constitute the random vector.\n",
    "\n",
    "Given the finite and nondeterministic nature of these observations, the estimate of the covariance matrix includes some amount of noise.\n",
    "\n",
    "Empirical covariance matrices derived from estimated factors are also numerically ill-conditioned, because those factors are also estimated from flawed data. Unless we treat this noise, it will impact the calculations we perform with the covariance matrix, sometimes to the point of rendering the analysis useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Marcenko–Pastur Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Observations $x$ of size $T$ x $N$\n",
    "- Underlying process generating observations with zero mean and variance $\\sigma^2$\n",
    "- $C = T^{-1} X' X$ has eigenvalues $\\lambda$ that asymptotically follow the Marcenko–Pastur distribution\n",
    "\n",
    "$$ f[\\lambda] = \\begin{cases} \\frac{T}{N} \\frac{\\sqrt{(\\lambda_+ - \\lambda)(\\lambda - \\lambda_-)}}{2\\pi\\lambda\\sigma^2} & \\text{if } \\lambda \\in [\\lambda_- , \\lambda_+] \\\\ 0 & \\text{if } \\lambda \\notin [\\lambda_- , \\lambda_+] \\end{cases} $$\n",
    "\n",
    "With expected maximum eigenvalue $\\lambda_+ = (1 + \\sqrt{\\frac{N}{T}})^2 \\sigma^2$ and expected minimum eigenvalue $\\lambda_- = (1 - \\sqrt{\\frac{N}{T}})^2 \\sigma^2$\n",
    "\n",
    "Eigenvalues $\\lambda \\in [\\lambda_- , \\lambda_+]$ are consistent with random behavior, and eigenvalues $\\lambda \\notin [\\lambda_- , \\lambda_+]$ are consistent with non-random behavior. Specifically we associate eigenvalues $\\lambda \\in [0, \\lambda_+]$ with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "\n",
    "def mpPDF(var,q,pts):\n",
    "    # Marcenko-Pastur pdf\n",
    "    # q=T/N\n",
    "    eMin,eMax = var * (1 - (1. / q)**.5)**2, var * (1 + (1. / q)**.5)**2\n",
    "    eVal = np.linspace(eMin, eMax, pts)\n",
    "    pdf = q / (2 * np.pi * var * eVal) * ((eMax - eVal) * (eVal - eMin))**.5\n",
    "    pdf = pd.Series(pdf, index=eVal)\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Marcenko–Pastur Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def getPCA(matrix):\n",
    "    # Get eVal, eVec from a Hermitian matrix\n",
    "    eVal, eVec = np.linalg.eigh(matrix)\n",
    "    indices = eVal.argsort()[::-1] # arguments for sorting eVal desc\n",
    "    eVal, eVec = eVal[indices], eVec[:,indices]\n",
    "    eVal = np.diagflat(eVal)\n",
    "    return eVal, eVec\n",
    "\n",
    "def fitKDE(obs, bWidth=.25, kernel='gaussian', x=None):\n",
    "    # Fit kernel to a series of obs, and derive the prob of obs\n",
    "    # x is the array of values on which the fit KDE will be evaluated\n",
    "    if len(obs.shape) == 1:\n",
    "        obs=obs.reshape(-1,1)\n",
    "    \n",
    "    kde = KernelDensity(kernel=kernel,bandwidth=bWidth).fit(obs)\n",
    "    \n",
    "    if x is None:\n",
    "        x = np.unique(obs).reshape(-1,1)\n",
    "    \n",
    "    if len(x.shape) == 1:\n",
    "        x = x.reshape(-1,1)\n",
    "    logProb = kde.score_samples(x) # log(density)\n",
    "    pdf = pd.Series(np.exp(logProb), index=x.flatten())\n",
    "    return pdf\n",
    "\n",
    "# Test the above functions\n",
    "x = np.random.normal(size=(10000,1000))\n",
    "eVal0, eVec0 = getPCA(np.corrcoef(x, rowvar=0))\n",
    "pdf0 = mpPDF(1.,q=x.shape[0] / float(x.shape[1]), pts=1000)\n",
    "pdf1 = fitKDE(np.diag(eVal0), bWidth=.01) # empirical pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=pdf1.index, y=pdf1.values, name='Empirical'))\n",
    "fig.add_trace(go.Scatter(x=pdf0.index, y=pdf0.values, name='Marcenko-Pastur'))\n",
    "fig.update_layout(title='Marcenko-Pastur vs Empirical PDF',\n",
    "                  xaxis_title='Eigenvalue λ',\n",
    "                  yaxis_title='Probability[λ]',\n",
    "                  width=800,\n",
    "                  height=800,\n",
    "                  xaxis_range=[0, 2]\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Marcenko–Pastur Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to discriminate between eigenvalues attributed to signal and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to add signal to noise\n",
    "\n",
    "def getRndCov(nCols,nFacts):\n",
    "    w = np.random.normal(size=(nCols, nFacts))\n",
    "    cov = np.dot(w,w.T) # random cov matrix, however not full rank\n",
    "    cov += np.diag(np.random.uniform(size=nCols)) # full rank cov\n",
    "    return cov\n",
    "\n",
    "def cov2corr(cov):\n",
    "    # Derive the correlation matrix from a covariance matrix\n",
    "    std = np.sqrt(np.diag(cov))\n",
    "    corr = cov / np.outer(std,std)\n",
    "    corr[corr<-1], corr[corr>1]=-1, 1 # numerical error\n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, nCols, nFact, q = .995, 1000, 100, 10\n",
    "cov = np.cov(np.random.normal(size=(nCols*q,nCols)), rowvar=0)\n",
    "cov = alpha * cov + (1 - alpha) * getRndCov(nCols, nFact) # noise+signal\n",
    "corr0 = cov2corr(cov)\n",
    "eVal0,eVec0 = getPCA(corr0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the PDF by minimizing squared difference between analytical marcenko-pastur distribution and kernel density estimate of eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errPDFs(var,eVal,q,bWidth,pts=1000):\n",
    "    # Fit error\n",
    "\n",
    "    # scipy minimize puts all vars in a vector, so define a function to unpack \n",
    "    if type(var) == np.ndarray:\n",
    "        var = var[0]\n",
    "\n",
    "    pdf0 = mpPDF(var, q, pts) # theoretical pdf\n",
    "    pdf1 = fitKDE(eVal, bWidth, x=pdf0.index.values) # empirical pdf\n",
    "    sse = np.sum((pdf1 - pdf0)**2)\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def findMaxEval(eVal, q, bWidth):\n",
    "    \n",
    "    # Find max random eVal by fitting Marcenko’s dist\n",
    "    out = minimize(lambda *x: errPDFs(*x), .5, args=(eVal, q, bWidth), bounds=((1E-5, 1-1E-5),))\n",
    "    \n",
    "    if out['success']:\n",
    "        var = out['x'][0]\n",
    "    else:\n",
    "        var = 1\n",
    "    eMax = var * (1 + (1. / q)**.5)**2\n",
    "    return eMax, var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "- eigenvalue cutoff $\\lambda_+$\n",
    "- noise variance $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the marcenko-pastur distribution\n",
    "eMax0, var0 = findMaxEval(np.diag(eVal0), q, bWidth=.01)\n",
    "nFacts0 = eVal0.shape[0] - np.diag(eVal0)[::-1].searchsorted(eMax0)\n",
    "\n",
    "# compute pdfs for plotting\n",
    "eValArr = np.diag(eVal0)\n",
    "\n",
    "pdf0 = mpPDF(var0, q=nCols/nFacts0, pts=1000)\n",
    "pdf1 = fitKDE(eValArr, bWidth=.01)\n",
    "\n",
    "# compute histogram of eValArr\n",
    "hist, bins = np.histogram(eValArr, bins=1000, density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Variance that is explained by the random eigenvectors: \", var0)\n",
    "print(\"Cutoff level for eigenvalues: \", eMax0)\n",
    "print(\"Percent of variance attributed to signal: \", 1-var0)\n",
    "print(\"Signal to noise ratio: \", (1-var0)/var0)\n",
    "\n",
    "# Plotting\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=bins, y=hist, name='Empirical (Histogram)'))\n",
    "fig.add_trace(go.Scatter(x=pdf0.index, y=pdf0.values, name='Marcenko-Pastur'))\n",
    "fig.add_trace(go.Scatter(x=pdf1.index, y=pdf1.values, name='Empirical'))\n",
    "fig.update_layout(title='Empirical PDF of Eigenvalues',\n",
    "                  xaxis_title='Eigenvalue λ',\n",
    "                  yaxis_title='Probability[λ]',\n",
    "                  width=1000,\n",
    "                  height=800,\n",
    "                  xaxis_range=[0, 7]\n",
    "                  )\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods:\n",
    "- Constant Residual Eigenvalue\n",
    "- Shrinkage\n",
    "\n",
    "Problem:\n",
    "- Noise and Signal are both shrinked by the same amount so it can make a weak signal disappear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Residual Eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoisedCorr(eVal,eVec,nFacts):\n",
    "    # Remove noise from corr by fixing random eigenvalues\n",
    "    eVal_=np.diag(eVal).copy()\n",
    "    eVal_[nFacts:]=eVal_[nFacts:].sum() / float(eVal_.shape[0]-nFacts)\n",
    "    eVal_=np.diag(eVal_)\n",
    "    corr1=np.dot(eVec,eVal_).dot(eVec.T)\n",
    "    corr1=cov2corr(corr1)\n",
    "    return corr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr1 = denoisedCorr(eVal0, eVec0, nFacts0)\n",
    "eVal1, eVec1 = getPCA(corr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot eigenvalues\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(eVal0)), y=np.log(np.diag(eVal0)), name='Original'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(eVal1)), y=np.log(np.diag(eVal1)), name='Denoised'))\n",
    "fig.update_layout(title='Eigenvalues of Correlation Matrix',\n",
    "                  xaxis_title='Eigenvalue Index',\n",
    "                  yaxis_title='Eigenvalue (log-scaled)',\n",
    "                  width=1000,\n",
    "                  height=800,\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "print(LA.cond(corr0))\n",
    "print(LA.cond(corr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoised by Targeted Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoisedCorr2(eVal,eVec,nFacts,alpha=0):\n",
    "    # Remove noise from corr through targeted shrinkage\n",
    "    eValL,eVecL=eVal[:nFacts,:nFacts],eVec[:,:nFacts]\n",
    "    eValR,eVecR=eVal[nFacts:,nFacts:],eVec[:,nFacts:]\n",
    "    corr0=np.dot(eVecL,eValL).dot(eVecL.T)\n",
    "    corr1=np.dot(eVecR,eValR).dot(eVecR.T)\n",
    "    corr2=corr0+alpha*corr1+(1-alpha)*np.diag(np.diag(corr1))\n",
    "    return corr2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr1 = denoisedCorr2(eVal0,eVec0,nFacts0,alpha=.5)\n",
    "eVal1, eVec1 = getPCA(corr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot eigenvalues\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(eVal0)), y=np.log(np.diag(eVal0)), name='Original'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(eVal1)), y=np.log(np.diag(eVal1)), name='Denoised'))\n",
    "fig.update_layout(title='Eigenvalues of Correlation Matrix',\n",
    "                  xaxis_title='Eigenvalue Index',\n",
    "                  yaxis_title='Eigenvalue (log-scaled)',\n",
    "                  width=1000,\n",
    "                  height=800,\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to remove a market component which affects all other eigenvalues. Important for clustering where the algorithm struggles to find dissimilarities between clusters.\n",
    "\n",
    "Detoning is the principal components analysis analogue to computing beta-adjusted (or market-adjusted) returns in regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not interesting for me at the moment maybe implement later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
